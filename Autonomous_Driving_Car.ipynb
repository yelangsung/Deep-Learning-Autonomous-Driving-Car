{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yelangsung/Deep-Learning-Autonomous-Driving-Car/blob/main/Autonomous_Driving_Car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHhTZZmYiHjX"
      },
      "source": [
        "<STEP 1> Google 드라이브 연결, 이미지 파일 압축 풀기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVUvp1PNiP5x"
      },
      "outputs": [],
      "source": [
        "epochN = None; learnRate = None                                                 # epochN = 2~10, learnRate = 0.0005/0.0010/0.0015/0.0020/0.0025\n",
        "import glob, zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')                                                   # Google Drive 연결\n",
        "imageDir = 'Car'; outDir = '/content/drive/MyDrive/'+imageDir\n",
        "fileList = glob.glob(outDir+'/*.zip'); print(f'Project N : {len(fileList)} 개')\n",
        "for t in fileList:\n",
        "    u = t.split('/'); v = u[-1]; w = v.split('.'); p = w[-2]; print(p)          # file list 생성\n",
        "project = input('Project Name :')\n",
        "if project == '': project = p\n",
        "local_zip =  '/content/drive/MyDrive/'+imageDir+'/'+project+'.zip'; print(local_zip)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r'); zip_ref.extractall(); zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZFNRpDrwx_o"
      },
      "source": [
        "<STEP 2> 라이브러리 (Import)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQZoAksnjCi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fba8eb-ce9b-4489-89f0-0fc28a2bdb7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version:     3.8.16 (default, Dec  7 2022, 01:12:13) \n",
            "[GCC 7.5.0]\n",
            "OpenCV version:     4.6.0\n",
            "Pytorch version:    1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import fnmatch\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2 as cv                                 # Open Cv 영상처리 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "print(f'Python Version:     {sys.version}')                                     # Python Version\n",
        "print(f'OpenCV version:     {cv.__version__}')                                  # Open CV version\n",
        "print(f'Pytorch version:    {torch.__version__}')                               # Pytorch version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA5CRv_sw3XN"
      },
      "source": [
        "<STEP 3> 이미지 데이터 조향각 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TvCY7hQjkYx"
      },
      "outputs": [],
      "source": [
        "dataDir = '/content/'+project                                                   # colab 내부 프로젝트 디렉터리\n",
        "with open(f'{dataDir}/{project}.pickle', 'rb') as f:                            # pickle\n",
        "    x_exam_Image = pickle.load(f)                                               # 시험 이미지 파일 이름 list\n",
        "    x_valid_Image = pickle.load(f)                                              # 평가 이미지 파일 이름 list\n",
        "    x_train_Image = pickle.load(f)                                              # 훈련 이미지 파일 이름 list\n",
        "    p = pickle.load(f)                                                          # Parameter list\n",
        "if epochN == None:    epochN =    p[0]                                          # 학습회수 2 ~ 10\n",
        "if learnRate == None: learnRate = p[1]                                          # 학습 비율 0.0005/0.0010/0.0015/0.0020/0.0025\n",
        "#-------------------------------------------------------------------------------\n",
        "y_exam_Angle=[]\n",
        "y_valid_Angle=[]\n",
        "y_train_Angle = []\n",
        "for f in x_exam_Image:                   # 시험용 이미지 파일 이름에서 각도값\n",
        "    y_exam_Angle.append(int(f[-7:-4]))\n",
        "for f in x_valid_Image:                  # 평가용 이미지 파일 이름에서 각도값\n",
        "    y_valid_Angle.append(int(f[-7:-4]))\n",
        "for f in x_train_Image:                  # 훈련용 이미지 파일 이름에서 각도값\n",
        "    y_train_Angle.append(int(f[-7:-4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP5tACd_xMJh"
      },
      "source": [
        "<STEP 4> Nvidia CNN 모델 구성, 딥러닝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxPuU_aI0iWv"
      },
      "outputs": [],
      "source": [
        "# Pytorch device 설정\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is available')\n",
        "\n",
        "# Nvidia CNN 모델 구성 ---------------------------------------------------------\n",
        "class NvidiaModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(NvidiaModel, self).__init__()\n",
        "\n",
        "      # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "      # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
        "\n",
        "      # Convolution Layers\n",
        "      self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=24, kernel_size=(5, 5), stride=(2, 2)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Conv2d(in_channels=24, out_channels=36, kernel_size=(5, 5), stride=(2, 2)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Conv2d(in_channels=36, out_channels=48, kernel_size=(5, 5), stride=(2, 2)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Conv2d(in_channels=48, out_channels=64, kernel_size=(3, 3)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3)),\n",
        "        nn.ELU(inplace=True)\n",
        "      )\n",
        "\n",
        "      # Fully Connected Layers\n",
        "      self.layer2 = nn.Sequential(\n",
        "        # nn.Flatten(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(in_features=18 * 64, out_features=100),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Linear(in_features=100, out_features=50),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Linear(in_features=50, out_features=10),\n",
        "        nn.ELU(inplace=True)\n",
        "      )\n",
        "\n",
        "      # Output Layer\n",
        "      self.layer3 = nn.Sequential(\n",
        "        nn.Linear(in_features=10, out_features=1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.layer1(x)\n",
        "      x = x.view(x.shape[0], -1)\n",
        "      x = self.layer2(x)\n",
        "      x = self.layer3(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "def imgPaths(fGroup):\n",
        "    r = []\n",
        "    for filename in fGroup:\n",
        "        r.append(os.path.join(dataDir, filename))                               # 파일 경로(path)를 화일 이름 앞에 부착하여 리스트에 추가\n",
        "    return(r)\n",
        "\n",
        "# 학습 데이터 생성 -------------------------------------------------------------\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, imageList, angleList):\n",
        "        self.imageList = imgPaths(imageList)\n",
        "        self.angleList = angleList\n",
        "\n",
        "        for i in range(len(imageList)):\n",
        "            # print(i, self.imageList[i])\n",
        "            image = cv.imread(self.imageList[i])\n",
        "            image = image / 255\n",
        "\n",
        "            self.imageList[i] = image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageList)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        images = torch.FloatTensor(self.imageList[index]).permute(2,0,1)\n",
        "        angles = torch.FloatTensor([self.angleList[index]])\n",
        "\n",
        "        return images, angles\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path=f'{outDir}/{project}_model_check.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        # torch.save(model, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "# 모델 학습 --------------------------------------------------------------------\n",
        "def learnProc():\n",
        "  model = NvidiaModel().to(device)\n",
        "\n",
        "  train_dataset = CustomDataset(x_train_Image, y_train_Angle)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=len(x_train_Image))\n",
        "\n",
        "  valid_dataset = CustomDataset(x_valid_Image, y_valid_Angle)\n",
        "  valid_loader = DataLoader(valid_dataset, batch_size=len(x_valid_Image))\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learnRate)\n",
        "  criterion = nn.MSELoss().to(device)\n",
        "\n",
        "  early_stopping = EarlyStopping(patience=30, verbose=True)\n",
        "\n",
        "  # EPOCHS = epochN\n",
        "  EPOCHS = 300\n",
        "  train_losses = []\n",
        "  valid_losses = []\n",
        "  avg_train_losses = []\n",
        "  avg_valid_losses = []\n",
        "  for epoch in range(1, EPOCHS + 1):\n",
        "      # 학습\n",
        "      model.train()\n",
        "\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          output = model(data)\n",
        "\n",
        "          loss = criterion(output.to(torch.float32), target.to(torch.float32))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_losses.append(loss.item())\n",
        "\n",
        "      # 검증\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss = criterion(output.to(torch.float32), target.to(torch.float32))\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "      train_loss = np.average(train_losses)\n",
        "      valid_loss = np.average(valid_losses)\n",
        "      avg_train_losses.append(train_loss)\n",
        "      avg_valid_losses.append(valid_loss)\n",
        "\n",
        "      epoch_len = len(str(EPOCHS))\n",
        "\n",
        "      print_msg = (f'[{epoch:>{epoch_len}}/{EPOCHS:>{epoch_len}}] ' +\n",
        "                      f'train_loss: {train_loss:.5f} ' +\n",
        "                      f'valid_loss: {valid_loss:.5f}')\n",
        "\n",
        "      print(print_msg)\n",
        "\n",
        "      train_losses = []\n",
        "      valid_losses = []\n",
        "\n",
        "      early_stopping(valid_loss, model)\n",
        "\n",
        "      if early_stopping.early_stop:\n",
        "          print(\"Early stopping\")\n",
        "          break\n",
        "\n",
        "  return {'loss':avg_train_losses, 'val_loss':avg_valid_losses}\n",
        "\n",
        "# 학습 시작---------------------------------------------------------------------\n",
        "print()\n",
        "print('시험 이미지 개수:',len(x_exam_Image))\n",
        "print('평가 이미지 개수:',len(x_valid_Image))\n",
        "print('훈련 이미지 개수:',len(x_train_Image))\n",
        "print('학습 비율=', learnRate)\n",
        "print('학습 회수=', epochN)\n",
        "print()\n",
        "startTime = time.time()                                                         # 학습 시작 시간 저장\n",
        "history = learnProc()                                                           # 학습 시작\n",
        "elapsedTime = int(time.time() - startTime)                                      # 학습 경과 시간 저장\n",
        "#-------------------------------------------------------------------------------\n",
        "plt.plot(history['loss'],color='blue')\n",
        "plt.plot(history['val_loss'],color='red')\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.savefig(f'{outDir}/{project}_result.png')                                   # plot 이미지 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqDQYO1MxjHF"
      },
      "source": [
        "<STEP 5> 학습 결과 표시, 테스트 파일 각도 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGICxni7ikSK"
      },
      "outputs": [],
      "source": [
        "def resultShow():\n",
        "  test_dataset = CustomDataset(x_exam_Image, y_exam_Angle)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=len(x_exam_Image))\n",
        "\n",
        "  model = NvidiaModel().to(device)\n",
        "  model.load_state_dict(torch.load(f'{outDir}/{project}_model_check.pt'))\n",
        "  # model = torch.load(f'{outDir}/{project}_model_check.pt')\n",
        "  model.eval()\n",
        "\n",
        "  y_pred = []\n",
        "  y_target = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            print('pred', output.to(device).numpy())\n",
        "            print('target', target.to(device).numpy())\n",
        "\n",
        "            for output_data, target_data in zip(output.to(device).numpy(), target.to(device).numpy()):\n",
        "              y_pred.append(output_data)\n",
        "              y_target.append(target_data)\n",
        "\n",
        "  mse = mean_squared_error(y_target, y_pred)\n",
        "  r2s = r2_score(y_target, y_pred)\n",
        "  #-----------------------------------------------------------------------------\n",
        "  print('\\n표준 편차:', f'{mse:.2}')\n",
        "  print('회귀 결정 계수:', f'{r2s:.2%}')\n",
        "  #-----------------------------------------------------------------------------\n",
        "  fig, axes = plt.subplots(1, len(x_exam_Image), figsize=(30, 2+3))\n",
        "  xTImg = imgPaths(x_exam_Image)                                                # 파일 이름 앞에 경로(path) 추가\n",
        "  for x, c in enumerate(xTImg):\n",
        "      axes[x].imshow(Image.open(c))\n",
        "      t = x_exam_Image[x] +' / E:'+str(int(y_pred[x]))\n",
        "      axes[x].set_title(t)\n",
        "      axes[x].xaxis.set_ticks([])\n",
        "      axes[x].yaxis.set_ticks([])\n",
        "\n",
        "if len(x_exam_Image): resultShow()\n",
        "print(\"학습 소요 시간:\", int(elapsedTime/60), '분', elapsedTime%60, '초' )      # 학습 소요시간 프린트"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}